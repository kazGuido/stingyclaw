
# ─── Model config ────────────────────────────────────────────────────────────
# OpenRouter API key — get one free at https://openrouter.ai
# Use "ollama" as the key for local Ollama
OPENROUTER_API_KEY=sk-or-v1-...

# Model to use. Examples:
#   liquid/lfm-2.5                          (free on OpenRouter, good tool use)
#   google/gemini-flash-1.5                 (free tier)
#   mistralai/mistral-7b-instruct:free      (free, lighter)
#   anthropic/claude-3-haiku                (cheap, fast)
#   openai/gpt-4o-mini                      (cheap)
#   llama3.2                                (local Ollama — any installed model)
MODEL_NAME=liquid/lfm-2.5

# API base URL.
# OpenRouter (default): https://openrouter.ai/api/v1
# Local Ollama:         http://host.docker.internal:11434/v1
# Local LM Studio:      http://host.docker.internal:1234/v1
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Optional: Gemini CLI for heavy coding tasks inside the agent container
# Get a free key at https://aistudio.google.com → Get API Key
# GEMINI_API_KEY=AIza...
